#!/usr/bin/env python3

import argparse # 用于解析命令行参数
import os
from chakra.third_party.utils.protolib import encodeMessage as encode_message
from chakra.et_def.et_def_pb2 import (
    Node as ChakraNode,
    DoubleList,
    FloatList,
    Int32List,
    Int64List,
    Uint32List,
    Uint64List,
    Sint32List,
    Sint64List,
    Fixed32List,
    Fixed64List,
    Sfixed32List,
    Sfixed64List,
    BoolList,
    StringList,
    BytesList,
    GlobalMetadata,
    AttributeProto as ChakraAttr,
    METADATA_NODE,
    MEM_LOAD_NODE,
    MEM_STORE_NODE,
    COMP_NODE,
    COMM_SEND_NODE,
    COMM_RECV_NODE,
    COMM_COLL_NODE,
    ALL_REDUCE,
    ALL_TO_ALL,
    ALL_GATHER,
    REDUCE_SCATTER,
)

# 全局变量，记录当前节点 ID，每创建一个新节点 ID 递增
NODE_ID = 0

def get_node(node_name: str, node_type: int) -> ChakraNode:
    """
    创建一个新的 ChakraNode，并分配唯一 ID
    """
    global NODE_ID
    node = ChakraNode()
    node.id = NODE_ID
    node.name = node_name
    node.type = node_type
    NODE_ID += 1
    return node


def get_comm_type_attr(comm_type: int) -> ChakraAttr:
    """
    返回一个表示通信类型的属性对象
    """
    return ChakraAttr(name="comm_type", int64_val=comm_type)


def get_involved_dim_attr(num_dims: int) -> ChakraAttr:
    """
    生成一个包含指定维度数的布尔列表属性
    """
    return ChakraAttr(name="involved_dim", bool_list=BoolList(values=[True] * num_dims))


def one_metadata_node_all_types(num_npus: int, output_dir: str) -> None:
    """
    创建 METADATA_NODE 节点，并为其附加各种数据类型的属性
    """
    for npu_id in range(num_npus):
        output_filename = os.path.join(output_dir, f"one_metadata_node_all_types.{npu_id}.et")
        with open(output_filename, "wb") as et:
            encode_message(et, GlobalMetadata(version="0.0.4"))
            
            # 创建元数据节点
            node = get_node("METADATA_NODE", METADATA_NODE)

            # 添加各种类型的属性
            node.attr.append(ChakraAttr(name="double", double_val=1.2345, doc_string="double"))
            double_list = DoubleList(values=[1.2345, 2.3456])
            node.attr.append(ChakraAttr(name="double_list", double_list=double_list))

            node.attr.append(ChakraAttr(name="float", float_val=1.2345, doc_string="float"))
            float_list = FloatList(values=[1.2345, 2.3456])
            node.attr.append(ChakraAttr(name="float_list", float_list=float_list))

            node.attr.append(ChakraAttr(name="int32", int32_val=12345, doc_string="int32"))
            int32_list = Int32List(values=[12345, 23456])
            node.attr.append(ChakraAttr(name="int32_list", int32_list=int32_list))

            node.attr.append(ChakraAttr(name="int64", int64_val=9876543210, doc_string="int64"))
            int64_list = Int64List(values=[9876543210, 1234567890])
            node.attr.append(ChakraAttr(name="int64_list", int64_list=int64_list))

            node.attr.append(ChakraAttr(name="uint32", uint32_val=12345, doc_string="uint32"))
            uint32_list = Uint32List(values=[12345, 23456])
            node.attr.append(ChakraAttr(name="uint32_list", uint32_list=uint32_list))

            node.attr.append(ChakraAttr(name="uint64", uint64_val=9876543210, doc_string="uint64"))
            uint64_list = Uint64List(values=[9876543210, 1234567890])
            node.attr.append(ChakraAttr(name="uint64_list", uint64_list=uint64_list))

            node.attr.append(ChakraAttr(name="sint32", sint32_val=-12345, doc_string="sint32"))
            sint32_list = Sint32List(values=[12345, -23456])
            node.attr.append(ChakraAttr(name="sint32_list", sint32_list=sint32_list))

            node.attr.append(ChakraAttr(name="sint64", sint64_val=-9876543210, doc_string="sint64"))
            sint64_list = Sint64List(values=[9876543210, -1234567890])
            node.attr.append(ChakraAttr(name="sint64_list", sint64_list=sint64_list))

            node.attr.append(ChakraAttr(name="fixed32", fixed32_val=12345))
            fixed32_list = Fixed32List(values=[12345, 23456])
            node.attr.append(ChakraAttr(name="fixed32_list", fixed32_list=fixed32_list))

            node.attr.append(ChakraAttr(name="fixed64", fixed64_val=9876543210))
            fixed64_list = Fixed64List(values=[9876543210, 1234567890])
            node.attr.append(ChakraAttr(name="fixed64_list", fixed64_list=fixed64_list))

            node.attr.append(ChakraAttr(name="sfixed32", sfixed32_val=-12345))
            sfixed32_list = Sfixed32List(values=[12345, -23456])
            node.attr.append(ChakraAttr(name="sfixed32_list", sfixed32_list=sfixed32_list))

            node.attr.append(ChakraAttr(name="sfixed64", sfixed64_val=-9876543210))
            sfixed64_list = Sfixed64List(values=[9876543210, -1234567890])
            node.attr.append(ChakraAttr(name="sfixed64_list", sfixed64_list=sfixed64_list))

            node.attr.append(ChakraAttr(name="bool", bool_val=True, doc_string="bool"))
            bool_list = BoolList(values=[i % 2 == 0 for i in range(10)])
            node.attr.append(ChakraAttr(name="bool_list", bool_list=bool_list))

            node.attr.append(ChakraAttr(name="string", string_val="12345", doc_string="string"))
            string_list = StringList(values=[str(12345+i) for i in range(10)])
            node.attr.append(ChakraAttr(name="string_list", string_list=string_list))

            node.attr.append(ChakraAttr(name="bytes", bytes_val=bytes("12345", "utf-8")))
            bytes_list = BytesList(values=[bytes(str(12345+i), "utf-8") for i in range(10)])
            node.attr.append(ChakraAttr(name="bytes_list", bytes_list=bytes_list))

            encode_message(et, node)


def one_remote_mem_load_node(num_npus: int, tensor_size: int, output_dir: str) -> None:
    """
    创建一个远程内存加载节点
    """
    for npu_id in range(num_npus):
        output_filename = os.path.join(output_dir, f"one_remote_mem_load_node.{npu_id}.et")

        with open(output_filename, "wb") as et:
            encode_message(et, GlobalMetadata(version="0.0.4"))

            node = get_node("MEM_LOAD_NODE", MEM_LOAD_NODE)
            node.attr.append(ChakraAttr(name="is_cpu_op", bool_val=False))
            node.attr.append(ChakraAttr(name="tensor_size", uint64_val=tensor_size))
            encode_message(et, node)


def one_remote_mem_store_node(num_npus: int, tensor_size: int, output_dir: str) -> None:
    """
    创建一个计算节点
    """
    for npu_id in range(num_npus):
        output_filename = os.path.join(output_dir, f"one_remote_mem_store_node.{npu_id}.et")
        with open(output_filename, "wb") as et:
            encode_message(et, GlobalMetadata(version="0.0.4"))

            node = get_node("MEM_STORE_NODE", MEM_STORE_NODE)
            node.attr.append(ChakraAttr(name="is_cpu_op", bool_val=False))
            node.attr.append(ChakraAttr(name="tensor_size", uint64_val=tensor_size))
            encode_message(et, node)


def one_comp_node(num_npus: int, runtime: int, output_dir: str) -> None:
    """
    创建一个 All-Reduce 集合通信节点
    """
    for npu_id in range(num_npus):
        output_filename = os.path.join(output_dir, f"one_comp_node.{npu_id}.et")
        with open(output_filename, "wb") as et:
            encode_message(et, GlobalMetadata(version="0.0.4"))

            node = get_node("COMP_NODE", COMP_NODE)
            node.attr.append(ChakraAttr(name="is_cpu_op", bool_val=False))
            node.duration_micros = runtime
            encode_message(et, node)


def two_comp_nodes_independent(num_npus: int, runtime: int, output_dir: str) -> None:
    for npu_id in range(num_npus):
        output_filename = os.path.join(output_dir, f"two_comp_nodes_independent.{npu_id}.et")

        with open(output_filename, "wb") as et:
            encode_message(et, GlobalMetadata(version="0.0.4"))

            node = get_node("COMP_NODE", COMP_NODE)
            node.duration_micros = runtime
            node.attr.append(ChakraAttr(name="is_cpu_op", bool_val=False))
            encode_message(et, node)

            node = get_node("COMP_NODE", COMP_NODE)
            node.duration_micros = runtime
            node.attr.append(ChakraAttr(name="is_cpu_op", bool_val=False))
            encode_message(et, node)


def two_comp_nodes_dependent(num_npus: int, runtime: int, output_dir: str) -> None:
    """
    创建两个相互依赖的计算节点 (COMP_NODE)。
    - 第一个计算节点 (parent_node) 先执行。
    - 第二个计算节点 (child_node) 依赖于第一个节点的执行。
    """
    for npu_id in range(num_npus): # 遍历每个 NPU
        output_filename = os.path.join(output_dir, f"two_comp_nodes_dependent.{npu_id}.et")

        with open(output_filename, "wb") as et: # 以二进制写入模式打开文件
            encode_message(et, GlobalMetadata(version="0.0.4")) # 写入全局元数据

            # 创建父计算节点
            parent_node = get_node("COMP_NODE", COMP_NODE)  # 生成计算节点
            parent_node.duration_micros = runtime # 设置计算运行时间
            parent_node.attr.append(ChakraAttr(name="is_cpu_op", bool_val=False)) # 该计算节点不是 CPU 操作
            encode_message(et, parent_node) # 将父节点编码并写入文件

            # 创建子计算节点（依赖父计算节点）
            child_node = get_node("COMP_NODE", COMP_NODE) # 生成计算节点
            child_node.duration_micros = runtime # 设置计算运行时间
            child_node.data_deps.append(parent_node.id)  # 设置子节点的依赖关系
            child_node.attr.append(ChakraAttr(name="is_cpu_op", bool_val=False)) # 该计算节点不是 CPU 操作
            encode_message(et, child_node) # 将子节点编码并写入文件
 

def one_comm_coll_node_allreduce(num_npus: int, num_dims: int, comm_size: int, output_dir: str) -> None:
    """
    生成 All-Reduce 集合通信节点 (ALL_REDUCE)。
    """
    for npu_id in range(num_npus):
        output_filename = os.path.join(output_dir, f"one_comm_coll_node_allreduce.{npu_id}.et")

        with open(output_filename, "wb") as et: # 以二进制写入模式打开文件
            encode_message(et, GlobalMetadata(version="0.0.4")) # 写入全局元数据

            node = get_node("ALL_REDUCE", COMM_COLL_NODE)  # 生成集合通信节点
            node.attr.append(ChakraAttr(name="is_cpu_op", bool_val=False))  # 该节点不是 CPU 操作
            node.attr.append(get_comm_type_attr(ALL_REDUCE))  # 设置通信类型为 All-Reduce
            node.attr.append(ChakraAttr(name="comm_size", uint64_val=comm_size)) 
            attr = get_involved_dim_attr(num_dims) # 获取涉及的维度属性
            node.attr.append(attr) # 添加涉及维度属性
            encode_message(et, node)  # 将节点编码并写入文件


def one_comm_coll_node_alltoall(num_npus: int, num_dims: int, comm_size: int, output_dir: str) -> None:
    """
    生成 All-to-All 集合通信节点 (ALL_TO_ALL)。
    """
    for npu_id in range(num_npus):
        output_filename = os.path.join(output_dir, f"one_comm_coll_node_alltoall.{npu_id}.et")

        with open(output_filename, "wb") as et:
            encode_message(et, GlobalMetadata(version="0.0.4"))

            node = get_node("ALL_TO_ALL", COMM_COLL_NODE)  # 生成集合通信节点
            node.attr.append(ChakraAttr(name="is_cpu_op", bool_val=False))
            node.attr.append(get_comm_type_attr(ALL_TO_ALL))
            node.attr.append(ChakraAttr(name="comm_size", uint64_val=comm_size))
            attr = get_involved_dim_attr(num_dims)
            node.attr.append(attr)
            encode_message(et, node)


def one_comm_coll_node_allgather(num_npus: int, num_dims: int, comm_size: int, output_dir: str) -> None:
    for npu_id in range(num_npus):
        output_filename = os.path.join(output_dir, f"one_comm_coll_node_allgather.{npu_id}.et")

        with open(output_filename, "wb") as et:
            encode_message(et, GlobalMetadata(version="0.0.4"))

            node = get_node("ALL_GATHER", COMM_COLL_NODE)
            node.attr.append(ChakraAttr(name="is_cpu_op", bool_val=False))
            node.attr.append(get_comm_type_attr(ALL_GATHER))
            node.attr.append(ChakraAttr(name="comm_size", uint64_val=comm_size))
            attr = get_involved_dim_attr(num_dims)
            node.attr.append(attr)
            encode_message(et, node)


def one_comm_coll_node_reducescatter(num_npus: int, num_dims: int, comm_size: int, output_dir: str) -> None:
    for npu_id in range(num_npus):
        output_filename = os.path.join(output_dir, f"one_comm_coll_node_reducescatter.{npu_id}.et")

        with open(output_filename, "wb") as et:
            encode_message(et, GlobalMetadata(version="0.0.4"))

            node = get_node("REDUCE_SCATTER", COMM_COLL_NODE)
            node.attr.append(ChakraAttr(name="is_cpu_op", bool_val=False))
            node.attr.append(get_comm_type_attr(REDUCE_SCATTER))
            node.attr.append(ChakraAttr(name="comm_size", uint64_val=comm_size))
            attr = get_involved_dim_attr(num_dims)
            node.attr.append(attr)
            encode_message(et, node)


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Execution Trace Generator" # 解析器的描述信息
    )

    # 添加命令行参数，用户可以自定义不同的参数值
    parser.add_argument(
        "--num_npus",
        type=int,
        default=64,
        help="Number of NPUs" # 设定NPU的数量，默认值是64
    )
    parser.add_argument(
        "--num_dims",
        type=int,
        default=2,
        help="Number of dimensions in the network topology" # 设定网络拓扑的维度数，默认是2维
    )
    # 添加参数：计算节点的默认运行时间（以微秒为单位）
    parser.add_argument(
        "--default_runtime",
        type=int,
        default=5,
        help="Default runtime of compute nodes"
    )

    # 添加参数：内存节点的默认张量大小
    parser.add_argument(
        "--default_tensor_size",
        type=int,
        default=1024,
        help="Default tensor size of memory nodes"
    )

    # 添加参数：通信节点的默认通信大小（字节）
    parser.add_argument(
        "--default_comm_size",
        type=int,
        default=65536,
        help="Default communication size of communication nodes"
    )
    args = parser.parse_args()

    # 自动生成目录名称
    output_dir = f"output/NPU_{args.num_npus}_Dim_{args.num_dims}_Runtime_{args.default_runtime}_Tensor_{args.default_tensor_size}_Comm_{args.default_comm_size}/"

    # 确保目录存在
    os.makedirs(output_dir, exist_ok=True)


    # 生成一个包含所有数据类型的元数据节点
    one_metadata_node_all_types(args.num_npus, output_dir)


    # 生成远程内存加载和存储节点
    one_remote_mem_load_node(args.num_npus, args.default_tensor_size, output_dir)
    one_remote_mem_store_node(args.num_npus, args.default_tensor_size, output_dir)

    # 生成计算节点
    one_comp_node(args.num_npus, args.default_runtime, output_dir)
    two_comp_nodes_independent(args.num_npus, args.default_runtime, output_dir)
    two_comp_nodes_dependent(args.num_npus, args.default_runtime, output_dir)

    # 生成集合通信节点（All-Reduce、All-to-All、All-Gather、Reduce-Scatter）
    one_comm_coll_node_allreduce(args.num_npus, args.num_dims, args.default_comm_size, output_dir)
    one_comm_coll_node_alltoall(args.num_npus, args.num_dims, args.default_comm_size, output_dir)
    one_comm_coll_node_allgather(args.num_npus, args.num_dims, args.default_comm_size, output_dir)
    one_comm_coll_node_reducescatter(args.num_npus, args.num_dims, args.default_comm_size, output_dir)



if __name__ == "__main__":

    main()
